{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a11e5d-b62b-4b17-b253-59d45e80f727",
   "metadata": {},
   "source": [
    "# Assignment 2 - Spark Dataframes\n",
    "***Note***: All the dataset files were stored in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda4be81-c73e-459b-a426-209b94e4631b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2619dca7550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "conf = pyspark.SparkConf()\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b389af-e9a2-4c6a-8c08-7fdb347fbac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. 15 Points\n",
    "**Datafile**: BreadBasket_DMS.csv\n",
    "\n",
    "**Solve**: What is the most popular (most sold) between the 8:00AM and 8:59AM for each day?\n",
    "\n",
    "Example output (not actual solution)\n",
    "\n",
    "    2016-10-30, Pastry\n",
    "\n",
    "    2016-10-31, Coffee\n",
    "     :\n",
    "     :\n",
    "\n",
    "### Approach:\n",
    "1. Import `BreadBasket_DMS.csv` into a dataframe\n",
    "2. Extract dates in `YYYY-MM-DD` format from the `Date` column and times in `hh:mm:ss` format from the `Time` column\n",
    "3. Filter the data by `Time` in the range of `08:00:00` and `08:59:00` inclusive and remove rows with `None` in the `Item` column\n",
    "4. Group the data by `Date` and `Item`, aggregate the `sum` of `Transaction` for each `Item` aliased as `Total` and, sort by `Date` and `Total`\n",
    "5. Group the data by `Date` and return the last `Item` and last `Total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798a4acf-2cd2-43d5-90f4-91593e1139e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|      Date|Most Popular Iteam|Total Transactions|\n",
      "+----------+------------------+------------------+\n",
      "|2016-10-31|             Bread|               165|\n",
      "|2016-11-01|               Tea|               542|\n",
      "|2016-11-02|            Coffee|              2064|\n",
      "|2016-11-03|            Coffee|              1382|\n",
      "|2016-11-04|            Coffee|               883|\n",
      "|2016-11-05|             Bread|              3164|\n",
      "|2016-11-07|            Coffee|               739|\n",
      "|2016-11-08|             Bread|               816|\n",
      "|2016-11-09|             Bread|               890|\n",
      "|2016-11-10|            Coffee|              1879|\n",
      "|2016-11-11|             Bread|              6067|\n",
      "|2016-11-12|         Medialuna|              1104|\n",
      "|2016-11-14|         Medialuna|              2555|\n",
      "|2016-11-15|  Keeping It Local|              1343|\n",
      "|2016-11-16|             Bread|              1409|\n",
      "|2016-11-17|          Siblings|              2953|\n",
      "|2016-11-18|            Coffee|              9313|\n",
      "|2016-11-19|            Coffee|              4895|\n",
      "|2016-11-21|            Coffee|              3604|\n",
      "|2016-11-22|         Medialuna|              1847|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Import BreadBasket_DMS.csv into a dataframe and `filter` out rows with `NONE` in the `Item` column\n",
    "from pyspark.sql.functions import col\n",
    "BreadBasket_DMS = spark.read.option(\"header\", True).option(\"InferSchema\", True).csv(\"BreadBasket_DMS.csv\")\n",
    "BreadBasket_DMS = BreadBasket_DMS.filter(col(\"Item\") != \"NONE\")\n",
    "\n",
    "# 2. Extract dates in `YYYY-MM-DD` format from the `Date` column and times in `hh:mm:ss` format from the `Time` column\n",
    "from pyspark.sql.functions import to_date, date_format\n",
    "BreadBasket_DMS = BreadBasket_DMS.withColumn(\"Date\", to_date(col(\"Date\"), \"YYYY-MM-DD\"))\n",
    "BreadBasket_DMS = BreadBasket_DMS.withColumn(\"Time\", date_format(col(\"Time\"),\"hh:mm:ss\"))\n",
    "\n",
    "# 3. Filter the data by `Time` in the range of `08:00:00` and `08:59:00` inclusive \n",
    "q1 = BreadBasket_DMS\n",
    "q1 = q1.filter((col(\"Time\") <= \"08:59:00\") & (col(\"Time\") >= \"08:00:00\"))\n",
    "\n",
    "# 4. Group the data by `Date` and `Item`, aggregate the `sum` of `Transaction` for each `Item` aliased as `Total` and, sort by `Date` and `Total`\n",
    "from pyspark.sql.functions import sum\n",
    "q1 = q1.groupBy(\"Date\",\"Item\").agg(sum(\"Transaction\").alias(\"Total\")).sort(\"Date\",\"Total\")\n",
    "\n",
    "# 5. Group the data by `Date` and return the last `Item` and last `Total`\n",
    "from pyspark.sql.functions import last\n",
    "q1 = q1.groupBy(\"Date\").agg(last(\"Item\").alias(\"Most Popular Iteam\"),last(\"Total\").alias(\"Total Transactions\"))\n",
    "\n",
    "# Display results\n",
    "q1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5749546-f3a2-46b4-8210-c86fa7c87502",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. 15 Points\n",
    "**Datafile**: BreadBasket_DMS.csv\n",
    "\n",
    "**Solve**: What is the most common item bought along with “Brownie”? (items bought in the same transaction)\n",
    "\n",
    "### Assumptions:\n",
    "We will assume that:\n",
    "1. Items bought at the same date and time as \"Brownie\" qualify as an item bought in the same transaction.\n",
    "2. \"most commom\" could imply the most number of total transactions or most number of occurences for the item. I will do both!\n",
    "3. An item only occurs once in an individual transaction.\n",
    "\n",
    "### Approach:\n",
    "1. Import `BreadBasket_DMS.csv` into a dataframe (See Q1)\n",
    "2. Extract dates in `YYYY-MM-DD` format from the `Date` column and times in `hh:mm:ss` format from the `Time` column (See Q1)\n",
    "3. Make list of Brownie Trans and Dates and Time\n",
    "4. Filter Brownie from list\n",
    "5. Join both\n",
    "#### Most Number of Total Transactions:\n",
    "\n",
    "#### Most Number of Occurences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90daa6a0-13db-4f5f-a13f-796a2df13589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------------------+\n",
      "|      Date|    Time|Transaction|                Item|\n",
      "+----------+--------+-----------+--------------------+\n",
      "|2016-11-03|01:02:37|        391|            Sandwich|\n",
      "|2016-11-03|01:02:37|        391|              Coffee|\n",
      "|2016-11-03|01:19:57|        392|              Pastry|\n",
      "|2016-11-03|01:19:57|        392|            Focaccia|\n",
      "|2016-11-03|01:19:57|        392|          Farm House|\n",
      "|2016-11-03|02:26:27|        403|                Cake|\n",
      "|2016-11-03|02:26:27|        403|              Pastry|\n",
      "|2016-11-03|03:55:46|        419|              Coffee|\n",
      "|2016-11-03|03:55:46|        419|           Alfajores|\n",
      "|2016-11-03|03:55:46|        419|Ella's Kitchen Po...|\n",
      "|2016-11-03|03:55:46|        419|               Juice|\n",
      "|2016-11-03|04:06:19|        421|             Cookies|\n",
      "|2016-11-03|04:06:19|        421|               Bread|\n",
      "|2016-11-03|04:06:19|        421|               Juice|\n",
      "|2016-11-03|04:06:19|        421|           Alfajores|\n",
      "|2016-11-03|10:39:12|        371|           Alfajores|\n",
      "|2016-11-03|10:39:12|        371|               Fudge|\n",
      "|2016-11-03|10:39:12|        371|              Coffee|\n",
      "|2016-11-03|12:05:25|        384|              Coffee|\n",
      "|2016-11-03|12:05:25|        384|            Sandwich|\n",
      "+----------+--------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 Brownie Transactions Date and Time\n",
    "BrownieTransactions = BreadBasket_DMS.filter(col(\"Item\") == \"Brownie\").select(\"Date\",\"Time\")\n",
    "\n",
    "# Non-Brownie Transactions\n",
    "OtherTransactions = BreadBasket_DMS.filter(col(\"Item\") != \"Brownie\")\n",
    "\n",
    "# Items bought with Brownies\n",
    "JoinExpression = (BrownieTransactions[\"Date\"] == OtherTransactions[\"Date\"]) & (BrownieTransactions[\"Time\"] == OtherTransactions[\"Time\"])\n",
    "ItemBougtWithBrownie = OtherTransactions.join(BrownieTransactions,JoinExpression, \"left_semi\").sort(\"Date\",\"Time\")\n",
    "ItemBougtWithBrownie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4737bb40-38d1-452a-bfce-abaa7d85de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|         Item|Transactions|\n",
      "+-------------+------------+\n",
      "|       Coffee|     1000233|\n",
      "|        Bread|      540798|\n",
      "|          Tea|      320766|\n",
      "|         Cake|      224202|\n",
      "|Hot chocolate|      179817|\n",
      "|      Cookies|      148147|\n",
      "|     Sandwich|      138445|\n",
      "|    Alfajores|      108437|\n",
      "|        Juice|      107391|\n",
      "|       Pastry|       85160|\n",
      "|    Medialuna|       72654|\n",
      "|        Scone|       66893|\n",
      "|         Coke|       60400|\n",
      "|         Soup|       56780|\n",
      "|   Farm House|       48390|\n",
      "|     Truffles|       47428|\n",
      "|       Muffin|       47178|\n",
      "|        Toast|       41480|\n",
      "|       Tiffin|       41090|\n",
      "|     Baguette|       37517|\n",
      "+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------------+----------+\n",
      "|             Item|Occurences|\n",
      "+-----------------+----------+\n",
      "|           Coffee|       237|\n",
      "|            Bread|       115|\n",
      "|              Tea|        71|\n",
      "|             Cake|        43|\n",
      "|    Hot chocolate|        42|\n",
      "|         Sandwich|        27|\n",
      "|        Alfajores|        27|\n",
      "|          Cookies|        26|\n",
      "|            Juice|        24|\n",
      "|           Pastry|        23|\n",
      "|        Medialuna|        19|\n",
      "|           Muffin|        18|\n",
      "|             Soup|        15|\n",
      "|            Scone|        12|\n",
      "|             Coke|        11|\n",
      "|       Farm House|        11|\n",
      "|         Truffles|        11|\n",
      "|    Mineral water|         9|\n",
      "|            Toast|         7|\n",
      "|Hearty & Seasonal|         6|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total Transactions\n",
    "from pyspark.sql.functions import desc, count, max\n",
    "a = ItemBougtWithBrownie.groupBy(\"Item\").agg(sum(\"Transaction\").alias(\"Transactions\")).sort(desc(\"Transactions\")).show()\n",
    "\n",
    "# Total Occurences\n",
    "ItemBougtWithBrownie.groupBy(\"Item\").agg(count(\"Item\").alias(\"Occurences\")).sort(desc(\"Occurences\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
